{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping a Website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we extract all poems by Nizar Qabbani from a selected website in order to build a large corpus of text for our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperlink_scraper(url, poem_list):\n",
    "    \"\"\"\n",
    "    returns all hyperlinks in a webpage in the form of:\n",
    "    - first link\n",
    "    - second link\n",
    "    - third link\n",
    "    ...\n",
    "    \n",
    "    Input:\n",
    "    - url(str): url to web page\n",
    "    - poem_list(list): array of htmls that is modified inside function\n",
    "    \n",
    "    \"\"\"\n",
    "    #read the page\n",
    "    html = urlopen(url)\n",
    "    #creapte a soup object\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    #find all hyperlinks\n",
    "    hyperlinks = soup.find_all('a')\n",
    "    \n",
    "    #loop over hyperlinks\n",
    "    for hyper in hyperlinks:\n",
    "        #if filed under poetry\n",
    "        if 'href=\"poetry.php?id=' in (str(hyper)):\n",
    "            #extract portion between double quotes + extract out of list\n",
    "            href = re.findall(r'\"([^\"]*)\"', str(hyper))[0]\n",
    "            #get in proper url\n",
    "            poem_html = 'https://www.nizariat.com/' + href\n",
    "            poem_list.append(poem_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store poems in empty list\n",
    "poem_list = []\n",
    "#base format of url\n",
    "base_url = 'https://www.nizariat.com/poertylist.php?page='\n",
    "for i in range(1, 12):\n",
    "    url = base_url+str(i)\n",
    "    hyperlink_scraper(url, poem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def write_poem(url, folder='data'):\n",
    "    #open the poem page\n",
    "    poem_html = urlopen(url)\n",
    "    \n",
    "    #make bs4 object\n",
    "    poem_soup = BeautifulSoup(poem_html, 'lxml')\n",
    "    \n",
    "    #get text inside paragraph\n",
    "    poem_par = poem_soup.findAll(\"div\", {\"class\": \"poettxt\"})[0]\n",
    "    \n",
    "    #get text from page\n",
    "    poem_text = poem_par.getText()\n",
    "\n",
    "    #make textfile name\n",
    "    filename = url[-3:]+'.txt'\n",
    "    write_loc = os.path.join(folder, filename)\n",
    "    \n",
    "    #writing mode\n",
    "    with open(write_loc, 'w') as f:\n",
    "        f.write(poem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each url write to file\n",
    "for poem in poem_list:\n",
    "    write_poem(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
